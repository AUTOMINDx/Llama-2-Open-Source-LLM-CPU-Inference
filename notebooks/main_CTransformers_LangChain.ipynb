{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b274f15",
   "metadata": {},
   "source": [
    "## GGML CTransformers Quantized models\n",
    "- References:\n",
    "    - https://python.langchain.com/en/latest/integrations/ctransformers.html\n",
    "    - https://python.langchain.com/en/latest/modules/models/llms/integrations/ctransformers.html\n",
    "    - https://github.com/marella/ctransformers#langchain\n",
    "    - https://github.com/marella/ctransformers#supported-models\n",
    "- Download GGML model bin from TheBloke: https://huggingface.co/TheBloke\n",
    "    - MPT-7B-Instruct downloads: https://huggingface.co/TheBloke/MPT-7B-Instruct-GGML/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d3b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import CTransformers, OpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e452a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {'max_new_tokens': 256, \n",
    "          'temperature': 0.1,\n",
    "#           'repetition_penalty': 1.1\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d0cc2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_BIN_PATH = '../models/bin/mpt-7b-instruct.ggmlv3.q5_1.bin'\n",
    "MODEL_BIN_PATH = '../models/bin/mpt-7b-instruct.ggmlv3.q8_0.bin'\n",
    "# MODEL_BIN_PATH = '../models/bin/mpt-7b-instruct.ggmlv3.fp16.bin'\n",
    "# MODEL_BIN_PATH = '../models/bin/ggml-mpt-7b-chat.bin'\n",
    "MODEL_TYPE = 'mpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd331cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenne\\Desktop\\GenAI-Chat\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "llm = CTransformers(model=MODEL_BIN_PATH, \n",
    "                    model_type=MODEL_TYPE,\n",
    "                    config=CONFIG\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15321e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = \"\"\"Question: {question}\n",
    "\n",
    "# Answer:\"\"\"\n",
    "\n",
    "# prompt = PromptTemplate(template=template, input_variables=['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddc0df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_chain = LLMChain(prompt=prompt, \n",
    "#                      llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a50a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# query = 'What is Boston Consulting Group?'\n",
    "# response = llm_chain.run(query)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e426b",
   "metadata": {},
   "source": [
    "___\n",
    "### Simulate Q&A Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da64c2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_system_template_prefix = \"\"\"\n",
    "# You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
    "\n",
    "# You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "\n",
    "# You have access to some personalized information provided by the human in the Context section below. \n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# qa_system_template_main = \"\"\"Use the following pieces of information to answer the human's question.\n",
    "# If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "# Context:\n",
    "# - Our Equality Policy ensures a representative and inclusive workplace, striving to \n",
    "# eliminate discrimination based on race, gender, disability, religion, age, sexual orientation, \n",
    "# or any other characteristic protected by the Equality Act 2010. \n",
    "# - Upholding the Employment Rights Act 1996, our Work-Life Balance Policy provides flexible working \n",
    "# arrangements for employees to balance their professional and personal lives. This policy, in compliance \n",
    "# with the UK Working Time Regulations 1998, also regulates work hours to prevent overwork.\n",
    "\n",
    "# Helpful answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c3a5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_qa_prompt():\n",
    "#     \"\"\"\n",
    "#     Prompt template for QA retrieval for each vectorstore\n",
    "#     \"\"\"\n",
    "#     messages = [\n",
    "# #         SystemMessagePromptTemplate.from_template(qa_system_template_prefix),\n",
    "#         SystemMessagePromptTemplate.from_template(qa_system_template_main),\n",
    "#         HumanMessagePromptTemplate.from_template('{question}')\n",
    "#         ]\n",
    "\n",
    "#     qa_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "    \n",
    "#     return qa_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e2e2773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_prompt = set_qa_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df2e5bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_template = \"\"\"You are an expert HR assistant. Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful detailed answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b56e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = PromptTemplate(template=new_template, \n",
    "                            input_variables=['context', 'question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2754366",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                                   model_kwargs={'device': 'cpu'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac106603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectordb\n",
    "vectordb = FAISS.load_local('../vectorstores/db_faiss', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f3fe885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_retrieval_qa(llm, prompt, vectordb):\n",
    "    dbqa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                       chain_type=\"stuff\",\n",
    "                                       retriever=vectordb.as_retriever(search_kwargs={\"k\": 2}),\n",
    "                                       return_source_documents=True,\n",
    "                                       chain_type_kwargs={\"prompt\": prompt}\n",
    "                                       )\n",
    "\n",
    "    return dbqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "415540ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbqa = build_retrieval_qa(llm, new_prompt, vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd170b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the length of maternity leave?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7235e796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = dbqa({'query': query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b531ca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the length of maternity leave?',\n",
       " 'result': ' Female employees are eligible for 26 weeks paid maternity leave.',\n",
       " 'source_documents': [Document(page_content='Copyright © 2019 by Boston Consulting Group. All rights reserved. 17Maternity benefit for birth mothers \\n•Female employee shall be entitled to 26 weeks (182 consecutive days \\nincluding weekends and Public Holidays) of paid maternity leave and shall be \\ntaken in one continuous block with no breaks in between.\\n•By local statutory, can start max 4 weeks before giving birth.\\n•Notice of pregnancy from a qualified medical practitioner must be submitted \\nto SEA Human Resources Operations team.', metadata={'source': 'data\\\\Employee Handbook 2023 SIN.pdf', 'page': 16}),\n",
       "  Document(page_content='to SEA Human Resources Operations team.\\n•All other provisions in the Employment Law relating to Maternity Leave are adopted herein and shall form an integral part of this Policy.\\n•Maternity leave does not break continuity of service with BCG.\\n•Employee from Consulting Team cohort does not accrue tenure credit while on maternity leave.\\nPaternity benefit for birth fathers \\n•Male employee shall be entitled to 8 weeks (56 consecutive days including', metadata={'source': 'data\\\\Employee Handbook 2023 SIN.pdf', 'page': 16})]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144ce26f",
   "metadata": {},
   "source": [
    "___\n",
    "## Performance Review\n",
    "#### mpt7b-instruct.ggmlv3.q5_1.bin (4.8Gb) - AMD Ryzen 5 5600X 6-Core Processor\n",
    "- query (with retrieval, k=3) = \"What is the length of maternity leave?\": CPU Wall time 42s\n",
    "- query (with retrieval, k=2) = \"What is the length of maternity leave?\": CPU Wall time 28s\n",
    " \n",
    "#### mpt-7b-instruct.ggmlv3.q8_0.bin (6.9Gb) - AMD Ryzen 5 5600X 6-Core Processor\n",
    "- query = 'What is Boston Consulting Group?': CPU Wall time 7.3s\n",
    "- query (with retrieval, k=3) = \"What is the length of maternity leave?\": CPU Wall time 30s\n",
    "- query (with retrieval, k=2) = \"What is the length of maternity leave?\": CPU Wall time 21s\n",
    "\n",
    "#### mpt-7b-instruct.ggmlv3.fp16.bin\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpter",
   "language": "python",
   "name": "gpter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
